{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatemafaria142/Banglish-to-Bangla-Machine-Translation-App-using-Streamlit/blob/main/Translation_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xccHTUA4drLj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.util import ngrams"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PzSkC1vPe4Z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Path**"
      ],
      "metadata": {
        "id": "OCM_T159LyA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the datasets\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/Banglish to Bangla/train_dataset.csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/Banglish to Bangla/test_dataset.csv\")\n",
        "validation_data = pd.read_csv(\"/content/drive/MyDrive/Banglish to Bangla/validation_dataset.csv\")\n",
        "\n",
        "# Remove extra white spaces from column names\n",
        "train_data.columns = train_data.columns.str.strip()\n",
        "test_data.columns = test_data.columns.str.strip()\n",
        "validation_data.columns = validation_data.columns.str.strip()\n"
      ],
      "metadata": {
        "id": "7PpZs5YwftMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head(5)"
      ],
      "metadata": {
        "id": "OejQOMqbgXBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.tail(5)"
      ],
      "metadata": {
        "id": "fL690gKN1fo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head(5)"
      ],
      "metadata": {
        "id": "8sBumGdygZoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.tail(5)"
      ],
      "metadata": {
        "id": "WpvaSQMc1kJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data.head(5)"
      ],
      "metadata": {
        "id": "xjJX-qYBgbOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data.tail(5)"
      ],
      "metadata": {
        "id": "V0-WYx7S1ptc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch pandas"
      ],
      "metadata": {
        "id": "gJjxfCbROQF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu"
      ],
      "metadata": {
        "id": "hjAFH_OYaGBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "id": "QbXwlOOKaNPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "o6vnIX2PcGE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "esPlJFmQe5lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!transformers-cli cache clear"
      ],
      "metadata": {
        "id": "NWIUgjZqcobw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface-cli"
      ],
      "metadata": {
        "id": "G6K8b1cG1wdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "id": "idYkCKoYLAkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "id": "ehyMslAiLEdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/csebuetnlp/normalizer"
      ],
      "metadata": {
        "id": "Y3y3J7pKLHo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip"
      ],
      "metadata": {
        "id": "o16Pwu4BRJED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers"
      ],
      "metadata": {
        "id": "TWyS4kEnRi-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import  MT5Model, AutoTokenizer, DataCollatorForSeq2Seq, Trainer, TrainingArguments\n",
        "from normalizer import normalize\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from sacrebleu import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "SY1P_thOZs0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the datasets\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/Banglish to Bangla/train_dataset.csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/Banglish to Bangla/test_dataset.csv\")\n",
        "validation_data = pd.read_csv(\"/content/drive/MyDrive/Banglish to Bangla/validation_dataset.csv\")\n",
        "\n",
        "# Remove extra white spaces from column names\n",
        "train_data.columns = train_data.columns.str.strip()\n",
        "test_data.columns = test_data.columns.str.strip()\n",
        "validation_data.columns = validation_data.columns.str.strip()\n"
      ],
      "metadata": {
        "id": "_r2KXdcLOII8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "id": "9N7XBlRTfUUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the columns to match the expected format\n",
        "train_data.rename(columns={'banglish_speech': 'input_text', 'bangla_speech': 'labels'}, inplace=True)\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "fFzjNm-5ojeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "id": "VyEST6yhfd89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the columns to match the expected format\n",
        "test_data.rename(columns={'banglish_speech': 'input_text', 'bangla_speech'\t: 'labels'}, inplace=True)\n",
        "test_data.head()"
      ],
      "metadata": {
        "id": "lx3Dgo0WgLSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data.head()"
      ],
      "metadata": {
        "id": "niWA4tjcfeDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the columns to match the expected format\n",
        "validation_data.rename(columns={'banglish_speech': 'input_text', 'bangla_speech'\t: 'labels'}, inplace=True)\n",
        "validation_data.head()"
      ],
      "metadata": {
        "id": "5md8H5UqgUkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface-cli"
      ],
      "metadata": {
        "id": "b4f1QM9Cq_Rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BanglaT5 model and Its Tokenizer**"
      ],
      "metadata": {
        "id": "eiXhvdBsq2Py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from normalizer import normalize # pip install git+https://github.com/csebuetnlp/normalizer\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"csebuetnlp/banglat5\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglat5\", use_fast=True) #sentencepiece library is required to instantiate the fast tokenizer\n"
      ],
      "metadata": {
        "id": "EsIxClpzOVGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "A_N5Dzib18PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Custom Dataset**"
      ],
      "metadata": {
        "id": "e5Hz-VSkyS73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=128):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data: A DataFrame containing 'input_text' and 'labels' columns.\n",
        "            tokenizer: A Hugging Face tokenizer.\n",
        "            max_length: Maximum sequence length.\n",
        "        \"\"\"\n",
        "        self.input_text = data['input_text'].apply(normalize).tolist()\n",
        "        self.labels = data['labels'].apply(normalize).tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_text)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_text = self.input_text[idx]\n",
        "        label_text = self.labels[idx]\n",
        "\n",
        "        # Tokenize the input text\n",
        "        input_encodings = self.tokenizer(\n",
        "            input_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Tokenize the label text to get its 'input_ids' and 'attention_mask'\n",
        "        label_encodings = self.tokenizer(\n",
        "            label_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_encodings['input_ids'].squeeze(),\n",
        "            'attention_mask': input_encodings['attention_mask'].squeeze(),\n",
        "            'labels': label_encodings['input_ids'].squeeze(),\n",
        "        }\n"
      ],
      "metadata": {
        "id": "pKGRnuEh0TGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train , test and validation datasets\n",
        "train_dataset = Seq2SeqDataset(train_data, tokenizer)\n",
        "test_dataset = Seq2SeqDataset(test_data, tokenizer)\n",
        "validation_dataset = Seq2SeqDataset(validation_data, tokenizer)\n",
        "\n",
        "# Create train , test and validation dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)  #batch_size=32\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16) #batch_size=32\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=16) #batch_size=32\n"
      ],
      "metadata": {
        "id": "LStEDAlZ1wYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the model to the device (CPU or GPU)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "Gd87PmBkeAY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# Create a custom optimizer using torch.optim.AdamW\n",
        "custom_optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=1e-3,  # Learning rate\n",
        "    eps=1e-8,  # Epsilon value to prevent division by zero\n",
        "    weight_decay=0.01,  # Weight decay (L2 regularization)\n",
        ")\n",
        "\n",
        "#if you have 1,000 training examples and a batch size of 100, you would have 10 iterations in each epoch (1,000 / 100 = 10)\n",
        "'''\n",
        "This parameter determines how many small batches are accumulated before performing a weight update.\n",
        "In your code, it's set to 8, which means you'll accumulate gradients over 8 small batches before performing a weight update.\n",
        "This effectively simulates a larger batch size without requiring more GPU memory.\n",
        "So, you are updating the model's weights less frequently compared to the number of actual batches processed.\n",
        "'''\n",
        "'''\n",
        "Learning rate determines how quickly the model learns from the data.\n",
        "The learning rate scheduler type is set to \"cosine_with_restarts,\" which is a type of learning rate schedule.\n",
        " Warmup steps are the number of initial training steps with a smaller learning rate, and weight decay introduces L2 regularization to the optimizer.\n",
        "'''\n",
        "'''\n",
        "Number of Iterations per Epoch = Number of Training Samples / Batch Size\n",
        "Total Iterations = Number of Iterations per Epoch * Number of Epochs\n",
        "'''\n",
        "# Define the TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/drive/MyDrive/Machine_Translation/banglish_to_bangla_translation_BanglaT5',\n",
        "    num_train_epochs=15,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=8,  # Accumulate gradients over 8 small batches\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    save_total_limit=2,\n",
        "    save_steps=500,\n",
        "    learning_rate=1e-3,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    remove_unused_columns=False,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        "    load_best_model_at_end=True,\n",
        "    lr_scheduler_type=\"cosine_with_restarts\",  # Set the learning rate scheduler type\n",
        "    warmup_steps=100,  # Number of warmup steps\n",
        "    weight_decay=0.01,  # Weight decay (L2 regularization)\n",
        "    logging_dir='/content/drive/MyDrive/Machine_Translation/banglish_to_bangla_translation_BanglaT5',  # Use the same directory for logs\n",
        "    logging_steps=500,  # Log every 500 steps\n",
        ")\n"
      ],
      "metadata": {
        "id": "lieCrycOdqHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "# Create a data collator for sequence-to-sequence tasks\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer,  # Your Hugging Face tokenizer\n",
        "    model=model,\n",
        "    padding=True,\n",
        "    max_length=128,\n",
        "    label_pad_token_id=tokenizer.pad_token_id,\n",
        ")"
      ],
      "metadata": {
        "id": "yM7jobxRCQ3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Trainer with the custom optimizer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        "    optimizers=(custom_optimizer, None),  # Pass the custom optimizer here\n",
        ")"
      ],
      "metadata": {
        "id": "Bc0oxhBLCRP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training start here**"
      ],
      "metadata": {
        "id": "wRbFX1xIvIuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "FXhfpwIuYqdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Saving model and tokenizer**"
      ],
      "metadata": {
        "id": "7F23E_DpvChu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained('/content/drive/MyDrive/Banglish to Bangla/bangla_translation_BanglaT5.pt')\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/Banglish to Bangla/bangla_tokenizer_BanglaT5.json')\n"
      ],
      "metadata": {
        "id": "HH4e0lrKVfGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer"
      ],
      "metadata": {
        "id": "AL4RCOHgU9tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the model to the device (CPU or GPU)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "7ySxLtGWb8eM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score\n",
        "#https://github.com/google-research/google-research/tree/master/rouge\n",
        "#https://huggingface.co/spaces/evaluate-metric/rouge [Different types of ROUGE scores]"
      ],
      "metadata": {
        "id": "V0oB40J3jc_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "EGt3awYZlEyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading evaluation metrics**"
      ],
      "metadata": {
        "id": "T-CckuFHvsvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from evaluate import load\n",
        "# Define the move_to_device function\n",
        "def move_to_device(batch, device):\n",
        "    if isinstance(batch, torch.Tensor):\n",
        "        return batch.to(device)\n",
        "    elif isinstance(batch, list):\n",
        "        return [move_to_device(item, device) for item in batch]\n",
        "    elif isinstance(batch, dict):\n",
        "        return {key: move_to_device(value, device) for key, value in batch.items()}\n",
        "    else:\n",
        "        return batch  # If it's not a tensor, list, or dict, leave it as is\n",
        "\n",
        "# Load the evaluation metric for Character Error Rate (CER) and Word Error Rate (WER) and Exact Match(em)\n",
        "cer_metric = load(\"cer\")\n",
        "wer_metric = load(\"wer\")\n",
        "meteor = load('meteor')\n",
        "exact_match_metric = load(\"exact_match\")\n",
        "\n",
        "# Load BLEU and ROUGE metrics\n",
        "bleu_metric = load(\"bleu\")\n",
        "rouge_metric = load('rouge')\n",
        "\n",
        "# Initialize lists to store generated translations and references\n",
        "generated_translations = []\n",
        "references = []\n",
        "\n",
        "# Generate translations for the test dataset\n",
        "for batch in test_dataloader:\n",
        "    # Move the batch to CUDA\n",
        "    batch = move_to_device(batch, 'cuda')\n",
        "\n",
        "    input_text = batch['input_ids']  # Access the input_text using the correct key\n",
        "    labels = batch['labels']  # Access the labels using the correct key\n",
        "\n",
        "    # Generate translations\n",
        "    translation_ids = model.generate(input_text, max_length=512, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
        "\n",
        "    # Move the translation_ids to CPU to decode\n",
        "    translation_ids = translation_ids.to('cpu')\n",
        "\n",
        "    generated_translation = tokenizer.batch_decode(translation_ids, skip_special_tokens=True)\n",
        "\n",
        "    generated_translations.extend(generated_translation)\n",
        "    references.extend(tokenizer.batch_decode(labels, skip_special_tokens=True))  # Decoding the label IDs\n"
      ],
      "metadata": {
        "id": "tFL6okK2jKb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of generated translations:\", len(generated_translations))\n",
        "print(\"Number of references:\", len(references))"
      ],
      "metadata": {
        "id": "q9IzRg_2jk4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_translations)"
      ],
      "metadata": {
        "id": "DTOYr3C-oJFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(references)"
      ],
      "metadata": {
        "id": "RsVL6kv2oQL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Character Error Rate (CER) and Word Error Rate (WER)\n",
        "results_CER = cer_metric.compute(predictions=generated_translations, references=references)\n",
        "results_WER = wer_metric.compute(predictions=generated_translations, references=references)\n",
        "\n",
        "# Calculate Exact Match (EM) and METEOR(M)\n",
        "results_em = exact_match_metric.compute(predictions=generated_translations, references=references)\n",
        "results_met = meteor.compute(predictions=generated_translations, references=references)\n",
        "\n",
        "# Calculate Bilingual Evaluation Understudy (BLEU) and Recall-Oriented Understudy for Gisting Evaluation (ROUGE)\n",
        "results_bleu = bleu_metric.compute(predictions=generated_translations, references=references)\n"
      ],
      "metadata": {
        "id": "wX5HA_74qZsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Printing every evaluation metrics**"
      ],
      "metadata": {
        "id": "Tyf8p-Ppv8ct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Character Error Rate for Banglish to Bangla Translation:\", results_CER)\n",
        "print(\"Word Error Rate for Banglish to Bangla Translation:\",results_WER)\n",
        "print(\"Exact Match for Banglish to Bangla Translation:\",results_em)\n",
        "print(\"BLEU Score for Banglish to Bangla Translation:\",results_bleu)\n",
        "print(\"METEOR for Banglish to Bangla Translation:\",results_met)\n"
      ],
      "metadata": {
        "id": "Q20W2nvCsVOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "id": "RwBd0cLyvw3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "from unidecode import unidecode\n",
        "\n",
        "# Initialize the Rouge scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=False)\n",
        "\n",
        "# Preprocess the text\n",
        "def preprocess_text(text):\n",
        "    text = unidecode(text)\n",
        "    tokens = text.split()\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Calculate scores for each pair of predictions and references\n",
        "rouge1_f1_scores = []\n",
        "rouge1_precision_scores = []\n",
        "rouge1_recall_scores = []\n",
        "rouge2_f1_scores = []\n",
        "rouge2_precision_scores = []\n",
        "rouge2_recall_scores = []\n",
        "rougeL_f1_scores = []\n",
        "rougeL_precision_scores = []\n",
        "rougeL_recall_scores = []\n",
        "\n",
        "for ref, pred in zip(references, generated_translations):\n",
        "    candidate = preprocess_text(pred)\n",
        "    reference = preprocess_text(' '.join(ref))\n",
        "    scores = scorer.score(reference, candidate)\n",
        "\n",
        "    rouge1_f1_scores.append(scores['rouge1'].fmeasure)\n",
        "    rouge1_precision_scores.append(scores['rouge1'].precision)\n",
        "    rouge1_recall_scores.append(scores['rouge1'].recall)\n",
        "    rouge2_f1_scores.append(scores['rouge2'].fmeasure)\n",
        "    rouge2_precision_scores.append(scores['rouge2'].precision)\n",
        "    rouge2_recall_scores.append(scores['rouge2'].recall)\n",
        "    rougeL_f1_scores.append(scores['rougeL'].fmeasure)\n",
        "    rougeL_precision_scores.append(scores['rougeL'].precision)\n",
        "    rougeL_recall_scores.append(scores['rougeL'].recall)\n",
        "\n",
        "# Calculate the average scores\n",
        "avg_rouge1_f1 = sum(rouge1_f1_scores) / len(rouge1_f1_scores)\n",
        "avg_rouge1_precision = sum(rouge1_precision_scores) / len(rouge1_precision_scores)\n",
        "avg_rouge1_recall = sum(rouge1_recall_scores) / len(rouge1_recall_scores)\n",
        "avg_rouge2_f1 = sum(rouge2_f1_scores) / len(rouge2_f1_scores)\n",
        "avg_rouge2_precision = sum(rouge2_precision_scores) / len(rouge2_precision_scores)\n",
        "avg_rouge2_recall = sum(rouge2_recall_scores) / len(rouge2_recall_scores)\n",
        "avg_rougeL_f1 = sum(rougeL_f1_scores) / len(rougeL_f1_scores)\n",
        "avg_rougeL_precision = sum(rougeL_precision_scores) / len(rougeL_precision_scores)\n",
        "avg_rougeL_recall = sum(rougeL_recall_scores) / len(rougeL_recall_scores)\n",
        "\n",
        "# Print the average scores\n",
        "print(\"Average Rouge-1 F1 Score:\", avg_rouge1_f1)\n",
        "print(\"Average Rouge-1 Precision:\", avg_rouge1_precision)\n",
        "print(\"Average Rouge-1 Recall:\", avg_rouge1_recall)\n",
        "\n",
        "print(\"Average Rouge-2 F1 Score:\", avg_rouge2_f1)\n",
        "print(\"Average Rouge-2 Precision:\", avg_rouge2_precision)\n",
        "print(\"Average Rouge-2 Recall:\", avg_rouge2_recall)\n",
        "\n",
        "print(\"Average Rouge-L F1 Score:\", avg_rougeL_f1)\n",
        "print(\"Average Rouge-L Precision:\", avg_rougeL_precision)\n",
        "print(\"Average Rouge-L Recall:\", avg_rougeL_recall)\n"
      ],
      "metadata": {
        "id": "_MJz-RsMvzMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary library for Hugging Face Hub authentication\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "# Authenticate to the Hugging Face Hub using the provided function\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "SphaDTJSskA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(\"Soyeda10/BanglishToBangla\")"
      ],
      "metadata": {
        "id": "PCilCULSsnNj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}